{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130cc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import model_to_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ee5752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c2cdb3deb14553b06f9d01cfcd9954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = '../../generated'\n",
    "behavior_data_dir = '../../behavior_data'\n",
    "story = 'pieman'\n",
    "original_transcript_dir = os.path.join(behavior_data_dir,'transcripts','moth_stories')\n",
    "with open(os.path.join(original_transcript_dir,'%s.txt'%story),'r') as f:\n",
    "    original_txt = f.read()\n",
    "\n",
    "device = 'cuda'\n",
    "model_name = 'Llama3-8b-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_to_path_dict[model_name]['hf_name'])\n",
    "model = LlamaForCausalLM.from_pretrained(model_to_path_dict[model_name]['hf_name'],attn_implementation=\"eager\",device_map='auto',torch_dtype = torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216cfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare prompt\n",
    "system_prompt = \"You are a human with limited memory ability. You're going to listen to a story, and your task is to recall the story and summarize it in your own words in a verbal recording. Respond as if you’re speaking out loud.\"\n",
    "user_prompt = \"Here's the story: %s\\nHere's your recall: \"%original_txt\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt,\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "tokenized_chat = tokenized_chat.to(device)\n",
    "recall_start_index = tokenized_chat.shape[1]-5\n",
    "\n",
    "# only apply the attention temperature manipulation from recall to the story, not to the system & user prompt\n",
    "# find where the story starts\n",
    "story_start_idx = -1\n",
    "for i,t in enumerate(tokenized_chat[0]):\n",
    "    txt = tokenizer.decode(t)\n",
    "    if ':' in txt:\n",
    "        story_start_idx = i+1\n",
    "        break\n",
    "assert story_start_idx>0 and story_start_idx<tokenized_chat.shape[1],'failed to find story start idx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9702f08",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|█▋        | 1/6 [01:41<08:26, 101.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|███▎      | 2/6 [03:04<06:02, 90.54s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 3/6 [04:34<04:30, 90.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|██████▋   | 4/6 [05:54<02:52, 86.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|████████▎ | 5/6 [07:15<01:24, 84.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|██████████| 6/6 [09:04<00:00, 90.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 30s, sys: 751 ms, total: 8min 31s\n",
      "Wall time: 9min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 30 recalls, total wall time 9 min\n",
    "# attention temperatures, 0 = unmodified, the larger the number, the higher the temperature, the more diffuse the attention\n",
    "scales = [0,0.00005,0.00007,0.0002,0.0005,0.001] \n",
    "n = 5 # generate 5 recalls per temp\n",
    "output_by_scale = {}\n",
    "for scale in tqdm(scales):\n",
    "    outputs = []\n",
    "    for i in range(n):\n",
    "        if scale != 0:\n",
    "            output = model.generate(tokenized_chat,attention_scale = scale,recall_start_index = recall_start_index,\n",
    "                                story_start_index=story_start_idx,max_new_tokens = 800,output_attentions=False,\n",
    "                                return_dict_in_generate=True,output_scores=False)\n",
    "        else:\n",
    "            output = model.generate(tokenized_chat,story_start_index=story_start_idx,max_new_tokens = 800,\n",
    "                                    output_attentions=False,return_dict_in_generate=True,output_scores=False)\n",
    "        sequence = output['sequences']\n",
    "        outputs.append(tokenizer.decode(sequence[0][tokenized_chat.shape[1]:]))\n",
    "    output_by_scale[scale] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64b6c3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let me try to recall the story... So, I started my journalism career in the Bronx at Fordham University, and I was a reporter for the student newspaper, The Ram. One day, I saw Dean McGowan, who was planning to raise tuition above the inflation rate, which would be a betrayal of Fordham's mission. I asked him about it, and just then, this figure appeared, holding a cream pie, and mashed it into the dean's face. The dean was covered in cream, and I went back to the newsroom to write the scoop.\n",
      "\n",
      "I pitched the story to my editor, Jim Dwyer, who's a senior and later won a Pulitzer Prize. He said, \"Dean McGowan, that guy's a dick, write it up!\" So, I wrote the story, and I added some embellishments, like giving the pie-thrower a name, Pie Man, and describing him as a cape-wearing, masked avenger. I also made up a catchphrase for him, \"Ego sum non an bestia,\" which means \"I am not an animal,\" but it doesn't make sense.\n",
      "\n",
      "The story ran on page one, and a few days later, I got a letter from Pie Man, saying he'd be at the steps of Duane Library at three o'clock. I went there with a photographer, and sure enough, Pie Man showed up, and he targeted Sheila Beale, the student body president. She was a well-bred, school-spirited student who had collaborated with Dean McGowan to ban outdoor drinking on campus.\n",
      "\n",
      "Pie Man became a sensation on campus, and people started dressing up like him and quoting him in class. The Ram ran five major stories about him, all written by me. Toward the end of this run, I saw Angela from my Brit Lit class at a bar, and she asked me if I was Pie Man. I knew that if I said yes, she'd have sex with me, so I said yes, and she asked me to buy her a beer and tell her all about it...<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# unmodifed attention\n",
    "print(output_by_scale[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff6832fe-f98e-4131-a2d0-3a81da32aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, I remember this guy, Dean McGowan, who was like, super important at Fordham University. And I was a reporter for the school paper, and I was trying to get a scoop on him. So, I went up to him and asked him some questions, and then this crazy thing happened - someone threw a cream pie in his face! I was like, \"Whoa, what's going on?\" And then I wrote a story about it, and it was a big deal on campus.\n",
      "\n",
      "So, I started calling the guy who threw the pie \"Pie Man,\" and I made up all this crazy stuff about him being a masked avenger and stuff. And then, Pie Man started leaving me notes and stuff, and I was like, \"Whoa, this guy is for real!\"\n",
      "\n",
      "And then, Pie Man started showing up all over campus, throwing pies at people and stuff. And people started dressing up like him and quoting him, and it was just this big thing. And I was like, the only one who knew what was going on, you know?\n",
      "\n",
      "And then, there was this girl, Angela, who was like, really into me, and she asked me if I was Pie Man. And I was like, \"Yeah, I'm Pie Man!\" And she was all, \"Oh, cool, buy me a beer and tell me all about it.\" And I was like, \"Yeah, sure thing!\" So, that's pretty much it. That's my story about Pie Man.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(output_by_scale[0.00005][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfd6a84e-99bf-4f1a-a8eb-3697c14bf26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so... I think the story was about me, and I was a journalist at Fordham University. I was talking to the dean, Dean McGowan, and he was being all secretive about raising tuition. Then, this guy, Pie Man, shows up and throws a cream pie in the dean's face! It was crazy! So, I wrote a story about it, and it got published in the school newspaper, The Ram. The editor, Jim Dwyer, was really impressed with my work, and he even went on to win a Pulitzer Prize.\n",
      "\n",
      "Anyway, Pie Man became a sensation on campus, and people started dressing up like him and quoting his catchphrase, \"Ego sum non an bestia,\" which means \"I am not an animal.\" I wrote a bunch of stories about him, and he even sent me a letter, saying he wanted to meet up again. So, I went to the meeting, and it was with the student body president, Sheila Beale. She was trying to ban outdoor drinking on campus, and Pie Man showed up again, throwing another cream pie!\n",
      "\n",
      "After that, people started to think I was Pie Man, and I even got asked out by this girl, Angela, from my Brit Lit class. She thought I was Pie Man, and I didn't correct her, because... well, it was just too easy. So, I went along with it, and we had a beer and talked about Pie Man. That's the story, I think...<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(output_by_scale[0.0002][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50214e7c-0ca8-4fbd-854b-b667cb8b340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I'm gonna try to remember the story... So, there was this guy who was a journalist, and he was working for this newspaper, and he was talking to this dean, and the dean was saying some stuff, and then this guy with a cream pie comes out of nowhere and smashes it in the dean's face! And then the journalist writes a story about it, and it becomes super popular, and people start calling the guy with the cream pie \"Pie Man\".\n",
      "\n",
      "So, Pie Man starts doing more and more pranks, and the journalist is like, \"Hey, I'm gonna write about this guy!\" And the journalist gives Pie Man a nickname, \"Pie Man\", and starts writing about him in the newspaper. And then, the journalist and Pie Man become friends, and they start doing more and more pranks together.\n",
      "\n",
      "And then, there's this girl, Angela, who's in the journalist's class, and she's all like, \"Hey, I think you're Pie Man!\" And the journalist's like, \"Yeah, I am!\" And then they start dating, and it's all very romantic.\n",
      "\n",
      "That's the story, I think... I hope that's right!<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(output_by_scale[0.0005][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformer]",
   "language": "python",
   "name": "conda-env-transformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
